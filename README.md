# ğŸ§  OmniScribe

**AI-Powered Knowledge Assistant with Multimodal Ingestion**

OmniScribe is an intelligent knowledge management system that ingests audio, images, and documents, stores them in a vector database, and answers questions using a local LLM with RAG (Retrieval-Augmented Generation).

---

## âœ¨ Features

- ğŸ¤ **Audio Transcription** - Whisper-powered speech-to-text
- ğŸ‘ï¸ **OCR Extraction** - PaddleOCR for text from images
- ğŸ“„ **Document Ingestion** - Support for TXT, MD, PDF, DOCX
- ğŸ” **Semantic Search** - ChromaDB vector database with BGE embeddings
- ğŸ¤– **Local LLM** - Llama 3.1 8B via Ollama (GPU accelerated)
- ğŸŒ **Web Research** - Tavily API fallback for unknown queries
- ğŸ”„ **Self-Learning** - Human feedback loop for corrections
- ğŸ³ **Docker Ready** - Full containerization with GPU support

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                      â”‚
â”‚              Nginx on port 80 (Docker)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend (FastAPI)                       â”‚
â”‚                     Port 8000                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Whisper    â”‚  PaddleOCR   â”‚  ChromaDB    â”‚  LangGraph â”‚
â”‚   (Audio)    â”‚   (Images)   â”‚  (VectorDB)  â”‚   (Agent)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚                    Ollama (LLM)                          â”‚
â”‚              Llama 3.1 8B - Port 11434                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Frontend | React 19, TypeScript, Tailwind CSS, Vite |
| Backend | FastAPI, Python 3.11, LangGraph |
| LLM | Ollama + Llama 3.1 8B |
| Audio | Faster-Whisper (whisper-small) |
| OCR | PaddleOCR |
| Vector DB | ChromaDB + BGE-Small embeddings |
| Web Search | Tavily API |
| Containerization | Docker, Docker Compose |

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Node.js 20+
- Ollama with `llama3.1:8b` model
- NVIDIA GPU (optional, for acceleration)

### Local Development

```bash
# Clone the repository
git clone https://github.com/yourusername/OmniScribe.git
cd OmniScribe

# Setup backend
cd backend
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
python setup_models.py  # Download AI models

# Start backend
python main.py

# In another terminal - Setup frontend
cd frontend
npm install
npm run dev
```

Access at: **http://localhost:5173**

### Docker Deployment

```bash
# Build and run all services
docker-compose up --build

# First time: warm up the LLM (takes ~2 min)
# Then enjoy fast responses!
```

Access at: **http://localhost**

---

## ğŸ“ Project Structure

```
OmniScribe/
â”œâ”€â”€ backend/              # FastAPI backend
â”‚   â”œâ”€â”€ main.py           # API endpoints
â”‚   â”œâ”€â”€ agent_engine.py   # LangGraph workflow
â”‚   â”œâ”€â”€ ingestion.py      # Whisper + PaddleOCR
â”‚   â”œâ”€â”€ vector_store.py   # ChromaDB connection
â”‚   â””â”€â”€ config.py         # Configuration
â”œâ”€â”€ frontend/             # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â”œâ”€â”€ services/     # API client
â”‚   â”‚   â””â”€â”€ App.tsx       # Main app
â”œâ”€â”€ docker/               # Docker config files
â”œâ”€â”€ models/               # Downloaded AI models
â”œâ”€â”€ knowledge/            # Documents for ingestion
â””â”€â”€ docker-compose.yml    # Container orchestration
```

---

## ğŸ”§ Configuration

Create a `.env` file in the project root:

```env
TAVILY_API_KEY=your_tavily_api_key_here
```

---

## ğŸ“– API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| POST | `/chat` | Query the knowledge base |
| POST | `/ingest/audio` | Upload audio file |
| POST | `/ingest/image` | Upload image for OCR |
| POST | `/ingest/text` | Upload document (txt/md/pdf/docx) |
| POST | `/ingest/scan` | Scan knowledge folder |
| POST | `/feedback` | Submit correction |

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.